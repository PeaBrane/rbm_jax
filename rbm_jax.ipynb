{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbm_jax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeaBrane/rbm_jax/blob/main/rbm_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an RBM using jax"
      ],
      "metadata": {
        "id": "R845_OKkjplN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook serves as a minimal example for training an RBM (restricted Boltzmann machine) using the ML framework, jax. It is designed to be a minimal introduction to the concept of unsupervised learning using stochastic neural networks, and also a proof-of-concept for the simplicity and power of the jax framework (in particular its jit compiler)."
      ],
      "metadata": {
        "id": "Awn3a56Wjx4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import ML libraries"
      ],
      "metadata": {
        "id": "aGKkMpqE1K0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we import all the necessary libraries from numpy, jax, and tensorflow. Note that these libraries are included in the Google Colab runtime environment. To enable efficient training with jax, make sure to enable the GPU accelerator in the runtime type if using Colab."
      ],
      "metadata": {
        "id": "IGpGD_HPdDUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gOE4wT0TYiVM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import rand, permutation\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.scipy.special import logit, expit\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the MNIST dataset"
      ],
      "metadata": {
        "id": "zQdAwNOv1UQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we download the MNIST dataset as numpy arrays from Keras, and rescale the image greyscales to range from 0 to 1."
      ],
      "metadata": {
        "id": "9XDihEcweABk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, x_train.shape[1]*x_train.shape[2]).astype('float32') / 256  # [data_size, n_visible]\n",
        "x_test = x_test.reshape(-1, x_test.shape[1]*x_test.shape[2]).astype('float32') / 256 # [data_size, n_visible]\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cMShYAijfIG",
        "outputId": "defcb35f-fa26-475c-b92e-df6d85a615e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before doing any unsupervised learning, let's first try to train a simple linear classifier on the dataset, so we have some baseline accuracy for reference later on. We should reach slightly above 90%."
      ],
      "metadata": {
        "id": "ZLprEN9NefHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracies(dataset, epochs, batch_size):\n",
        "  x_train, y_train, x_test, y_test = dataset\n",
        "\n",
        "  linear_classifier = tf.keras.Sequential(tf.keras.layers.Dense(10))\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"auto\", name='loss')\n",
        "  acc = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "  linear_classifier.compile(optimizer='adam', loss=loss, metrics=acc)\n",
        "  history = linear_classifier.fit(x_train, y_train, batch_size, epochs, validation_data=(x_test, y_test), verbose=0)\n",
        "\n",
        "  return history.history['accuracy'][-1], history.history['val_accuracy'][-1]\n",
        "\n",
        "\n",
        "train_acc, val_acc = accuracies((x_train, y_train, x_test, y_test), epochs=5, batch_size=256)\n",
        "\n",
        "print(f'train_acc: {train_acc:.3f}, val_acc: {val_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7hCSiZXzU6j",
        "outputId": "a978a908-0199-4f6a-bdee-07f887164c09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc: 0.914, val_acc: 0.917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing unsupervised learning"
      ],
      "metadata": {
        "id": "Spe7F3Z41YrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For most unsupervised learning problems without any labels, it is exponentially difficult to obtain the exact gradients of the weights (which requires iterating through all possible visible configurations). Instead, we approximate the gradients of the weights from statistics gathered by a Gibbs chain starting from the dataset, and conditionally sampling the visible/hidden activations in the RBM back and forth. \n",
        "\n",
        "This form of stochastic gradient update using a Gibbs chain is called contrastive divergence, or CD for short. This [set of notes](https://christian-igel.github.io/paper/TRBMAI.pdf) provides a detailed description of the CD algorithm. An update is called CD-k if the Gibbs chain passed through the RBM k times. We now try to implement efficiently in jax the standard CD-k algorithm."
      ],
      "metadata": {
        "id": "HmZwChepu3BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_divergence(inputs, weights, biases_visible, biases_hidden, iterations=1, lr=1e-2):\n",
        "  n_ensemble, batch_size, n_visible = inputs.shape\n",
        "  n_hidden = weights.shape[-1]\n",
        "\n",
        "  # initialize the visible layer as the input data, and the hidden layer as zeros\n",
        "  visible = inputs\n",
        "  hidden = jnp.zeros([n_ensemble, batch_size, n_hidden])\n",
        "\n",
        "  # pre-compute the random tensor used to sampling the neural activations later\n",
        "  rand_hidden = logit(rand(iterations, n_ensemble, batch_size, n_hidden))\n",
        "  rand_visible = logit(rand(iterations, n_ensemble, batch_size, n_visible))\n",
        "\n",
        "  # compute the exact gradient statistics conditioned on the dataset; this is the \"data term\" or \"positive gradient\"\n",
        "  grads_visible_data = visible\n",
        "  grads_hidden_data = jax.nn.sigmoid(jnp.einsum('cbi,cij->cbj', visible, weights) + biases_hidden[:, jnp.newaxis, ...])\n",
        "  grads_weights_data = jnp.einsum('cbi,cbj->cij', visible, grads_hidden_data) / batch_size\n",
        "  grads_visible_data, grads_hidden_data = grads_visible_data.mean(1), grads_hidden_data.mean(1)\n",
        "\n",
        "  # pre-allocate the memory for aggregating the gradient statistics gathered by the Gibbs chain\n",
        "  grads_weights = jnp.zeros([n_ensemble, n_visible, n_hidden])\n",
        "  grads_visible = jnp.zeros([n_ensemble, n_visible])\n",
        "  grads_hidden = jnp.zeros([n_ensemble, n_hidden])\n",
        "\n",
        "  # iterate the Gibbs chain\n",
        "  for iteration in jnp.arange(iterations):\n",
        "    # sample the hidden and visible activations\n",
        "    hidden = (jnp.einsum('cbi,cij->cbj', visible, weights) + biases_hidden[:, np.newaxis, :] > rand_hidden[iteration, ...]).astype('float32')\n",
        "    visible = (jnp.einsum('cbj,cij->cbi', hidden, weights) + biases_visible[:, np.newaxis, :] > rand_visible[iteration, ...]).astype('float32')\n",
        "\n",
        "    # aggregate the gradient statistics from the Gibbs chain; this is the \"model term\" or \"negative gradient\"\n",
        "    grads_weights += jnp.einsum('cbi,cbj->cij', visible, hidden) / batch_size\n",
        "    grads_hidden += hidden.mean(1)\n",
        "    grads_visible += visible.mean(1)\n",
        "\n",
        "  # update and return the weights and biases\n",
        "  weights += lr*(grads_weights_data - grads_weights / iterations)\n",
        "  biases_visible += lr*(grads_visible_data - grads_visible / iterations)\n",
        "  biases_hidden += lr*(grads_hidden_data - grads_hidden / iterations) \n",
        "  return weights, biases_visible, biases_hidden\n",
        "\n",
        "\n",
        "# we use jit (just-in-time) to compile the CD algorithm in jax, to further improve efficiency\n",
        "cd_jitted = jax.jit(contrastive_divergence, static_argnums=[4, 5])"
      ],
      "metadata": {
        "id": "8Imro2ZiYoSd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's initialize multiple independent RBMs and train them using CD at the same time. This may take a while (several minutes), so make yourself a cup of coffee."
      ],
      "metadata": {
        "id": "VtwKTG6D19c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_ensemble = 5  # number of independent RBMs to train\n",
        "epochs = 50\n",
        "iterations = 3  # iterations for contrastive divergence\n",
        "batch_size = 100\n",
        "learning_rates = np.geomspace(1e-1, 1e-3, epochs)\n",
        "\n",
        "data_size = x_train.shape[0]\n",
        "n_visible = x_train.shape[1]\n",
        "n_hidden = 128  # number of hidden neurons in the RBM\n",
        "\n",
        "# weight initialization (appropriately normalized)\n",
        "weights = jnp.array((-1 + 2*rand(n_ensemble, n_visible, n_hidden)) / np.sqrt(n_visible))\n",
        "biases_visible = jnp.array((-1 + 2*rand(n_ensemble, n_visible)) / np.sqrt(n_visible))\n",
        "biases_hidden = jnp.array((-1 + 2*rand(n_ensemble, n_hidden)) / np.sqrt(n_visible))\n",
        "\n",
        "for epoch, lr in zip(range(epochs), learning_rates):\n",
        "  # randomly shuffle the dataset and divide into batches for each training ensemble\n",
        "  permutes = np.vstack([permutation(data_size) for _ in range(n_ensemble)])\n",
        "  batches = np.split(x_train.take(permutes, axis=0), round(data_size / batch_size), axis=1)  # [ensembles, batch_size, n_visible] * batches\n",
        "\n",
        "  # run the CD algorithm batch-wise\n",
        "  for batch in batches:\n",
        "    batch = jnp.array(batch, dtype='float32')\n",
        "    weights, biases_visible, biases_hidden = cd_jitted(batch, weights, biases_visible, biases_hidden, iterations, lr)"
      ],
      "metadata": {
        "id": "qhDU2JVdcLSl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting the RBM"
      ],
      "metadata": {
        "id": "CqSLhCEiReQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can evaluate the RBMs we trained by attaching a linear classifier to the hidden layer, and see if the classifier does better on the features implicitly extracted by the RBMs. Note that the RBM weights are frozen so they don't see the labels.\n",
        "\n",
        "Turns out the accuracies did not improve by much compared to our previously established baseline (or attaching a linear classifier directly to the input data)..."
      ],
      "metadata": {
        "id": "VaRSDh5DQREQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_hidden = np.array(jnp.einsum('bi,cij->cbj', jnp.array(x_train), weights) + biases_hidden[:, np.newaxis, :])\n",
        "x_test_hidden = np.array(jnp.einsum('bi,cij->cbj', jnp.array(x_test), weights) + biases_hidden[:, np.newaxis, :])\n",
        "\n",
        "accs = [accuracies((x_train_hidden[ensemble], y_train, x_test_hidden[ensemble], y_test), epochs=5, batch_size=256) for ensemble in range(n_ensemble)]\n",
        "print('(train_acc, test_acc)')\n",
        "accs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIgGizDPzKx8",
        "outputId": "42de1c87-7f50-4ecd-9292-be8ea4ef3f0f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(train_acc, test_acc)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8892833590507507, 0.8974999785423279),\n",
              " (0.8916333317756653, 0.9014999866485596),\n",
              " (0.8856666684150696, 0.8944000005722046),\n",
              " (0.8928999900817871, 0.8996000289916992),\n",
              " (0.8932166695594788, 0.8982999920845032)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, there is one cool feature of the RBM we have not explored yet, and that is its generative nature. In short, we can try to \"interpolate\" between the input images, by performing a linear interpolating of the sampled hidden activations, and then passing these interpolations back to the visible layer to see how they look.\n",
        "\n",
        "In particular, if the RBM was able to extract non-trivial features in the hidden layer, then the input images will appear to gradually \"morph\" into each other, instead of being a trivial pixel-wise intensity interpolation between images. Let's check it out."
      ],
      "metadata": {
        "id": "UzVCAf7bRYG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G9QujzZ7RK3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from PIL import Image\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "n_images = 5  # number of images to interpolate between\n",
        "n_interps = 40  # number of interpolation frames between two images\n",
        "\n",
        "# sample the hidden activations with the trained RBMs\n",
        "x_slice = jnp.array(x_test[:n_images], dtype='float32')\n",
        "y_slice = jnp.einsum('bi,cij->bcj', x_slice, weights) + biases_hidden\n",
        "y_slice = (y_slice > logit(rand(n_images, n_ensemble, n_hidden))).astype('float32')\n",
        "\n",
        "y_slice = jnp.stack([y_slice[:-1, ...], y_slice[1:, ...]], axis=0).repeat(n_interps, axis=1)\n",
        "interp_ratios = jnp.linspace(0, 1, n_interps)\n",
        "y_interps = y_slice * \\\n",
        "  jnp.tile(jnp.stack([1-interp_ratios, interp_ratios], axis=0), [1, n_images-1])[..., jnp.newaxis, jnp.newaxis]\n",
        "y_interps = y_interps.sum(0)  # [n_frames, n_ensemble, image_size]\n",
        "\n",
        "x_interps = jnp.einsum('bcj,cij->bci', y_interps, weights) + biases_visible\n",
        "x_interps = expit(x_interps).reshape(-1, n_ensemble, 28, 28)  # [n_frames, n_ensemble, width, height]\n",
        "x_interps = np.array(x_interps)\n",
        "\n",
        "for x_interp in x_interps:\n",
        "  x_interp = np.concatenate([x_instance for x_instance in x_interp], axis=1)\n",
        "  imgs = Image.fromarray((x_interp * 256).clip(0, 255).astype('uint8'), 'L')\n",
        "  clear_output(wait=True)\n",
        "  display(imgs)\n",
        "  time.sleep(0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "ViQ0JZ4qgv12",
        "outputId": "b4a69f7d-fcf1-4e60-974b-bfbc5f970b41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=140x28 at 0x7F59420213D0>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}